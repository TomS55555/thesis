{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets.datasets import SHHSdataset\n",
    "from datasets.augmentations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find file at path:  ../../data/n1011_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1014_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1032_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1053_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1089_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1102_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1115_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1153_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1155_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1157_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1179_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1195_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1217_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1221_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1230_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1259_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1271_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1273_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1275_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1280_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1321_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1339_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1349_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1365_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1373_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1379_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1388_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1396_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1402_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1403_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1421_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1434_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1456_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1468_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1472_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1490_eeg.mat\n",
      "Couldn't find file at path:  ../../data/n1495_eeg.mat\n"
     ]
    }
   ],
   "source": [
    "ds = SHHSdataset(\n",
    "    data_path='../../data/',\n",
    "    first_patient=1000,\n",
    "    num_patients=500,\n",
    "    # exclude_test_set=(1,3),\n",
    "    # window_size=4\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datapoint: tensor([[[-0.1049, -0.3359, -0.3010,  ...,  0.4789,  0.8136,  0.8898]]])\n",
      "label: tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "datapoint, label = ds.__getitem__(7)\n",
    "print(\"datapoint: \"+str(datapoint))\n",
    "print(\"label: \"+str(label))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(-0.2013)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newpoint = datapoint.view(1,1,12000)\n",
    "newpoint[0,0,9000]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 768])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "layer = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=1,\n",
    "                      out_channels=128,\n",
    "                      kernel_size=7,\n",
    "                      stride=2,\n",
    "                      padding=3,\n",
    "                      bias=False),  # Output: 6000\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Conv1d(in_channels=128,\n",
    "                      out_channels=128,\n",
    "                      kernel_size=7,\n",
    "                      stride=2,\n",
    "                      padding=3,\n",
    "                      bias=False),  # Output: 3000\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Conv1d(in_channels=128,\n",
    "                      out_channels=128,\n",
    "                      kernel_size=7,\n",
    "                      stride=2,\n",
    "                      padding=3,\n",
    "                      bias=False),  # Output: 1500\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Conv1d(in_channels=128,\n",
    "                      out_channels=128,\n",
    "                      kernel_size=7,\n",
    "                      stride=2,\n",
    "                      padding=3,\n",
    "                      bias=False),  # Output: 750\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Conv1d(in_channels=128,\n",
    "                      out_channels=128,\n",
    "                      kernel_size=7,\n",
    "                      stride=2,\n",
    "                      padding=3,\n",
    "                      bias=False),  # Output: 375\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Conv1d(in_channels=128,\n",
    "                      out_channels=256,\n",
    "                      kernel_size=5,\n",
    "                      stride=2,\n",
    "                      padding=2,\n",
    "                      bias=False),  # Output: 188\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Conv1d(in_channels=256,\n",
    "                      out_channels=256,\n",
    "                      kernel_size=5,\n",
    "                      stride=2,\n",
    "                      padding=2,\n",
    "                      bias=False),  # Output: 94\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Conv1d(in_channels=256,\n",
    "                      out_channels=256,\n",
    "                      kernel_size=5,\n",
    "                      stride=2,\n",
    "                      padding=2,\n",
    "                      bias=False),  # Output: 47\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Conv1d(in_channels=256,\n",
    "                      out_channels=256,\n",
    "                      kernel_size=5,\n",
    "                      stride=2,\n",
    "                      padding=2,\n",
    "                      bias=False),  # Output: 24\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Conv1d(in_channels=256,\n",
    "                      out_channels=256,\n",
    "                      kernel_size=5,\n",
    "                      stride=2,\n",
    "                      padding=2,\n",
    "                      bias=False),  # Output: 12\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Conv1d(in_channels=256,\n",
    "                      out_channels=256,\n",
    "                      kernel_size=3,\n",
    "                      stride=2,\n",
    "                      padding=1,\n",
    "                      bias=False),  # Output: 6\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Conv1d(in_channels=256,\n",
    "                      out_channels=256,\n",
    "                      kernel_size=3,\n",
    "                      stride=2,\n",
    "                      padding=1,\n",
    "                      bias=False),  # Output: 3\n",
    "            nn.LeakyReLU(negative_slope=0.1),\n",
    "            nn.Flatten()  # Output: 768\n",
    "        )\n",
    "output = layer(newpoint)\n",
    "output.size()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "2214540000"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.X1.element_size()*ds.X1.nelement()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from datasets.datamodules import EEGdataModule\n",
    "import torch.utils.data as data\n",
    "dl = data.DataLoader(\n",
    "    ds,\n",
    "    batch_size=8192,\n",
    "    shuffle=True,\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "batch = next(iter(dl))\n",
    "eegs, labels = batch[0].to(device), batch[1].to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "12288000"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eegs.element_size()*eegs.nelement()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "del eegs, labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tomsm\\anaconda3\\lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:268: UserWarning: Attribute 'encoder' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['encoder'])`.\n",
      "  rank_zero_warn(\n",
      "C:\\Users\\tomsm\\anaconda3\\lib\\site-packages\\pytorch_lightning\\utilities\\parsing.py:268: UserWarning: Attribute 'projector' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['projector'])`.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "SimCLR(\n  (f): CNN_head(\n    (model): Sequential(\n      (0): CNN_block(\n        (net): Sequential(\n          (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n          (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n        )\n      )\n      (1): CNN_block(\n        (net): Sequential(\n          (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n          (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n        )\n      )\n      (2): CNN_block(\n        (net): Sequential(\n          (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n          (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n        )\n      )\n      (3): Flatten(start_dim=1, end_dim=-1)\n      (4): Linear(in_features=24000, out_features=100, bias=True)\n    )\n  )\n  (g): Linear(in_features=100, out_features=5, bias=True)\n  (net): Sequential(\n    (0): CNN_head(\n      (model): Sequential(\n        (0): CNN_block(\n          (net): Sequential(\n            (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n            (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n          )\n        )\n        (1): CNN_block(\n          (net): Sequential(\n            (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n            (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n          )\n        )\n        (2): CNN_block(\n          (net): Sequential(\n            (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n            (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n          )\n        )\n        (3): Flatten(start_dim=1, end_dim=-1)\n        (4): Linear(in_features=24000, out_features=100, bias=True)\n      )\n    )\n    (1): Linear(in_features=100, out_features=5, bias=True)\n  )\n)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models.simclr_model import SimCLR\n",
    "from models.mymodules import CNN_head\n",
    "import torch.nn as nn\n",
    "model = SimCLR(\n",
    "    encoder=CNN_head([32, 32, 64], 100),\n",
    "    projector=nn.Linear(100,5),\n",
    "    optim_hparams={\n",
    "        'lr': 1e-4,\n",
    "        'max_epochs': 10\n",
    "    },\n",
    "    temperature=1\n",
    ")\n",
    "model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "SimCLR(\n  (f): CNN_head(\n    (model): Sequential(\n      (0): CNN_block(\n        (net): Sequential(\n          (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n          (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n        )\n      )\n      (1): CNN_block(\n        (net): Sequential(\n          (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n          (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n          (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n        )\n      )\n      (2): CNN_block(\n        (net): Sequential(\n          (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n          (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU()\n          (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n        )\n      )\n      (3): Flatten(start_dim=1, end_dim=-1)\n      (4): Linear(in_features=24000, out_features=100, bias=True)\n    )\n  )\n  (g): Linear(in_features=100, out_features=5, bias=True)\n  (net): Sequential(\n    (0): CNN_head(\n      (model): Sequential(\n        (0): CNN_block(\n          (net): Sequential(\n            (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n            (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n          )\n        )\n        (1): CNN_block(\n          (net): Sequential(\n            (0): Conv1d(32, 32, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n            (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n            (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n          )\n        )\n        (2): CNN_block(\n          (net): Sequential(\n            (0): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=same, bias=False)\n            (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): ReLU()\n            (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n          )\n        )\n        (3): Flatten(start_dim=1, end_dim=-1)\n        (4): Linear(in_features=24000, out_features=100, bias=True)\n      )\n    )\n    (1): Linear(in_features=100, out_features=5, bias=True)\n  )\n)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
