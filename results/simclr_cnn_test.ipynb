{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "\n",
    "from datasets.SHHS_dataset_timeonly import SHHS_dataset_1, EEGdataModule\n",
    "\n",
    "from models.logistic_regression import LogisticRegression\n",
    "from models.simclr_model import SimCLR\n",
    "from models.supervised_model import SupervisedModel\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from argparse import Namespace\n",
    "from copy import deepcopy\n",
    "from utils.helper_functions import load_model, SimCLRdataModule"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Define dataset: 10 patients for training, 5 for validation and 30 for testing\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_args = {\n",
    "  \"DATA_PATH\": \"../../thesis01/data/\",\n",
    "  \"data_split\": [2, 1],\n",
    "  \"first_patient\": 1,\n",
    "  \"num_patients_train\": 15,\n",
    "  \"num_patients_test\": 30,\n",
    "  \"batch_size\": 64,\n",
    "  \"num_workers\": 12\n",
    "}\n",
    "\n",
    "device = torch.device('cpu')\n",
    "dm = EEGdataModule(**data_args)  # Load datamodule\n",
    "dm.setup()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Run data through the pretrained SimCLR encoder to get the representations\n",
    "- The SimCLR model was pretrained on 100 patients (+50 for validation)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "encoder_path = \"../trained_models/simclr05.ckpt\"\n",
    "pretrained_model = load_model(SimCLR, encoder_path)  # Load pretrained simclr model\n",
    "simclr_dm = SimCLRdataModule(pretrained_model, dm, data_args['batch_size'], data_args['num_workers'], device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Analyse the features: histogram and t-SNE plot\n",
    "feature = next(iter(simclr_dm.train_dataloader()))[0]\n",
    "plt.hist(np.asarray(feature), bins=50)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, n_iter=300, verbose=1, perplexity=125)\n",
    "x = torch.cat(list(dm.train_dataloader())[0])\n",
    "x, y = train_ds.tensors\n",
    "tsne_results = tsne.fit_transform(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['comp-1'] = tsne_results[:,0]\n",
    "df['comp-2'] = tsne_results[:,1]\n",
    "df[\"y\"] = y\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(\n",
    "    x=\"comp-1\", y=\"comp-2\",\n",
    "    hue=df.y.tolist(),\n",
    "    palette=sns.color_palette(\"hls\", 5),\n",
    "    data=df,\n",
    "    legend=\"full\",\n",
    "    alpha=0.3\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train a logistic classifier on top\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "logistic_args = {\n",
    "  \"MODEL_TYPE\": \"SupervisedModel\",\n",
    "  \"save_name\": \"logistic_on_simclr\",\n",
    "  \"DATA_PATH\": data_args['DATA_PATH'],\n",
    "  \"CHECKPOINT_PATH\": \"checkpoints\",\n",
    "\n",
    "  \"encoder\": \"None\",\n",
    "  \"encoder_hparams\": {},\n",
    "\n",
    "  \"classifier\": \"logistic\",\n",
    "  \"data_hparams\": data_args,\n",
    "\n",
    "  \"trainer_hparams\":{\n",
    "    \"max_epochs\": 15\n",
    "  },\n",
    "  \"optim_hparams\": {\n",
    "    \"lr\": 1e-3,\n",
    "    \"weight_decay\": 1e-4\n",
    "  }\n",
    "}\n",
    "from trainers.train_supervised import train_supervised\n",
    "model, res = train_supervised(Namespace(**logistic_args), device=device, dm=simclr_dm)\n",
    "print(res)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
